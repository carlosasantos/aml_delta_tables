{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a databricks notebook to create a delta table using a public dataset\n",
    "#### Please use the \"databricks_create_delta.dbc\" file to upload to databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f36f9fe3-97c0-4c5b-8bce-967319295cd0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from delta import configure_spark_with_delta_pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0ca208e-2590-4964-bde2-1886dfea8b0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "builder = (\n",
    "    pyspark.sql.SparkSession.builder.appName(\"example-app-delta\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f350e7c2-f8a2-4e34-9151-8b4cd8c626a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faac91f2-35f6-4ced-8d4d-e3519da80e34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.unmount(mount_point = \"/mnt/flightdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "184873e1-e1f6-46be-8c26-618fc3885e9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "client_id = ''\n",
    "client_secret = ''\n",
    "tenant_id = ''\n",
    "container_name = ''\n",
    "datalake_name = ''\n",
    "\n",
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "       \"fs.azure.account.oauth2.client.id\": client_id,\n",
    "       \"fs.azure.account.oauth2.client.secret\": client_secret,\n",
    "       \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\",\n",
    "       \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n",
    "\n",
    "dbutils.fs.mount(\n",
    "source = f\"abfss://{container_name}@{datalake_name}.dfs.core.windows.net/\",\n",
    "mount_point = \"/mnt/flightdata\",\n",
    "extra_configs = configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e143fa9-14b8-4e5d-8064-44594ec8cfbb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "ls -l /dbfs/mnt/flightdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "835cc59c-ec0b-48ea-8aed-fd0f6747628a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "wget https://github.com/Azure-Samples/AzureStorageSnippets/raw/master/blobs/tutorials/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2016_1.zip -P /dbfs/mnt/flightdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a725fca2-ec27-411a-85ad-cc9f8d84465b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "mkdir \"/dbfs/mnt/flightdata/Delta\"\n",
    "unzip /dbfs/mnt/flightdata/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2016_1.zip -d /dbfs/mnt/flightdata/\n",
    "mv \"/dbfs/mnt/flightdata/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2016_1.csv\" /dbfs/mnt/flightdata/On_Time.csv\n",
    "rm /dbfs/mnt/flightdata/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2016_1.zip\n",
    "rm /dbfs/mnt/flightdata/readme.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bd1cc90-1695-489b-87b7-536734305e3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "  # Use the previously established DBFS mount point to read the data.\n",
    "# create a data frame to read data.\n",
    "\n",
    "flightDF = spark.read.format('csv').options(\n",
    "    header='true', inferschema='true').load(\"/mnt/flightdata/*.csv\")\n",
    "\n",
    "# read the airline csv file and write the output to parquet format for easy query.\n",
    "# flightDF.write.mode(\"append\").parquet(\"/mnt/flightdata/parquet/flights\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22f047fa-9cd3-4fec-85df-08a6de7f7069",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# flightDF.write.format(\"delta\").saveAsTable(\"table1\")\n",
    "flightDF.write.format(\"delta\").mode(\"overwrite\").option('overwriteSchema','true').save(\"/mnt/flightdata/Delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c8f84f3-56b8-4655-803f-36b25938ad75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loaded_df = spark.read.format('delta').load('/mnt/flightdata/Delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9db92ed6-ecb4-4654-bdc8-fa101d585483",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(loaded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "768c8ca3-fa4c-4d44-8f39-60ae0bec4fa4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(flightDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e257b61e-04a2-47d3-b0a1-aef0dff00371",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "flightDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1774d9cc-e334-4e94-b183-d8690ea0c870",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loaded_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ea36e35-1dd2-4ff8-ae41-6990f6bc66f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 442008713884885,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "databricks_create_delta",
   "notebookOrigID": 567476393949822,
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
